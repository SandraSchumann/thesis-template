\chapter{Theorie}\label{ch:data}

\section{Grafische Benutzeroberfläche}
Der Begriff Benutzerschnittstelle bezeichnet alle Komponenten eines interaktiven Systems, die dem Benutzer Interaktionsmöglichkeiten mit selbigem System bieten um ein verfolgtes Ziel zu erreichen.
Die grafische Benutzeroberfläche (GUI) bezeichnet hierbei den sichtbaren Anteil des Systems und damit nur einen Teil der gesamten Benutzerschnittstelle, zu der auch nicht sichtbare Teile wie z.B. die Funktionslogik gehören\cite{Sarodnick.2016}.
Heutzutage sind die meisten Benutzeroberflächen auch grafische Benutzeroberflächen, mit denen in den häufigsten Fällen die Interaktion mit dem Nutzer über direkte Manipulation stattfindet\cite{Nielsen.1995?}.

\section{Ergonomie}
Unter Ergonomie versteht man im Allgemeinen die "Lehre von der menschlichen Arbeit und die Erkenntnis ihrer Gesetzmäßigkeiten"\cite{https:www.facebook.comArbeitsplatzergonomie.2014}.
Hierbei ist es wichtig zu verstehen, dass dabei der Fokus nicht ausschließlich auf einer technischen Komponente liegt, sondern das Zusammenspiel von Mensch, der zugeteilten Aufgabe und den verfügbaren Werkzeugen betrachtet wird\cite{Sarodnick.2016}.
Im Bezug auf Software bedeutet Ergonomie also konkret diese gut handhabbar und benutzerorientiert zu gestalten.

\section{Usability}
Mit immer höherer Komplexität von Systemen und Anwendungen kam der Begriff und das Verlangen nach  "Benutzerfreundlichkeit"\ auf.
Dieser Begriff suggeriert das lediglich die einfache Benutzung eines Systems ausschlaggebend ist, vernachlässigt hierbei jedoch die Notwendigkeit den Nutzer beim Erreichen seiner Ziele passend zu unterstützen.
Dies ist auch der Grund dafür das bald, statt auf "Benutzerfreundlichkeit"\ auf "Gebrauchstauglichkeit" (engl. Usability) geachtet wurde.
Im Gegensatz zur Ergonomie handelt es sich bei Usability nicht um eine eigenständige wissenschaftliche Disziplin, sondern um eine qualitative Anforderung an ein System\cite{Sarodnick.2016}.
Konkret spricht man bei einer Software-Anwendung von einer hohen Usability, wenn sie von der für sie bestimmten Zielgruppe effizient verwendet werden kann, also das verfolgte Ziel zufriedenstellend erreicht wird\cite{Richter.2016}.
Hierfür ist es entscheidend sich bewusst zu machen das ein technisches System oder Software immer Teil eines großen Handlungsablaufes ist und dazu dient Schritte dieses Handlungsablaufes zu erledigen.
Deshalb muss das System den Anforderungen dieses Ablaufes entsprechen und darf während der Entwicklung nicht getrennt davon betrachtet werden\cite{Sarodnick.2016}.

\section{User Experience}
Entgegen einer häufigen Annahme bezeichnen Usability und User Experience (UX) nicht das Gleiche.
Usability bezeichnet lediglich ein Teil der gesamten User Experience eines Systems\cite{Knight.2019c}.
UX bezieht sich nicht nur auf die reine Nutzungszeit eines Systems, sondern berücksichtigt auch den Zeitraum davor und danach, bezeichnet als Antizipierte Nutzung und Verarbeitung der Nutzungssituation.
Usability ist hierbei, wie in \cref{fig:UX} zu sehen,  als wichtiger Faktor der User Experience in der aktiven Nutzungsphase zu betrachten, jedoch nicht mit dem Begriff gleichzusetzen \cite{Sarodnick.2016}.
Durch die zusätzliche Betrachtung der Effekte auf den Nutzer vor und nach der Nutzung, wie beispielsweise Erwartungen an das Produkt und Akzeptanz des selbigen, entstehen hier auch Verbindungen zur Gestaltung der Benutzerschnittstelle und dem Produkt-Design\cite{Richter.2016}.
Zusammenfassend lässt sich festhalten das Usability zwar die funktionsbezogene Betrachtungsweise abdeckt, die User Experience als ganzes jedoch auch emotionale Faktoren bezüglich Design und Ästhetik berücksichtigt um das Nutzungsvergnügen möglichst hoch zu halten.
Zusätzlich ist eine gute User Experience notwendig wenn ein Produkt auf dem Markt bestehen will.
Sobald es mehr als ein Produkt zur Lösung der gleichen Aufgabenstellung gibt, wird das mit der besseren User Experience Verwendung finden\cite{Knight.2019c}.

\begin{figure} [!h]
\begin{center}
  \includegraphics[scale=0.7]{figures/UX.png}
  \caption{Zusammenhang Usability und User Experience (nach \cite{Sarodnick.2016})}
  \label{fig:UX}
\end{center}
\end{figure}

\newpage
\section{Human - Centered - Design - Process}
TODO

\begin{figure} [!h]
\begin{center}
  \includegraphics[width=\textwidth]{figures/HCD.png}
  \caption{Human - Centered - Design - Process bei Elektrobit}
  \label{fig:HCD}
\end{center}
\end{figure}

\section{Gestaltprinzipien der Usability}
TODO Ausformulieren

\cite{Norman.2016} Für Einleitung etwas suchen

\subsection*{Konsistenz}
Konsistenz im Design wirkt sich insofern positiv auf die Usability eines Systems aus, das die Benutzbarkeit steigt wenn gleiche Funktionen in einem System auch auf identische Art und Weise dargestellt werden.
Dadurch wird es dem Nutzer ermöglicht bereits Gelerntes in einem neuen Kontext anzuwenden, ohne effektiv darüber nachdenken zu müssen, neue Dinge schneller zu lernen und sich auf die relevanten Dinge einer Aufgabe zu konzentrieren.
Konsistenz in Systemen lässt sich in vier Kategorien unterteilen, die im Folgenden jeweils kurz erläutert werden.

\paragraph{Ästhetische Konsistenz}
Ästhetische Konsistenz bezieht sich auf Konsistenz in Stil und Aussehen. Dadurch entsteht ein hoher Wiedererkennungswert und es wird Zugehörigkeit signalisiert. Das einfachste Beispiel hierfür ist ein Firmenlogo, welches immer mit konsistenter Schriftart und Farbgebung auftaucht.

\paragraph{Funktionale Konsistenz}
Funktionale Konsistenz bezieht sich auf die Konsistenz von Bedeutung und Aktion, beispielsweise zeigt eine Ampel immer orange bevor sie rot wird. Der Nutzer kann also sicher mit einer immer gleichen darauffolgenden Aktion auf den aktuellen Zustand rechnen. 
Die Usability und Lernfähigkeit wird durch funktionale Konsistenz erhöht, indem diese bereits verinnerlichten Abläufe einfach auf neue Situationen übertragen werden können. So wird beispielsweise ein einheitlicher Playbutton für alle Geräte, von Kassettenrekorder bis Streamingdienst, verwendet.
Die Nutzung bereits bekannter Symbole ermöglicht dem Nutzer also eine intuitive Interaktion und macht es möglich die Aufmerksamkeit auf unbekannte Aspekte zu richten, die tatsächlich noch neu gelernt werden müssen.

\paragraph{Interne Konsistenz}
Interne Konsistenz bezieht sich auf Konsistenz mit anderen Elementen im System, beispielsweise sind Wegweiser in einem Park konsistent zueinander.
Dies erzeugt ein Vertrauensgefühl bei den Nutzern, und vermittelt ein durchdachtes Designkonzept und erweckt nicht den Eindruck das alle Komponenten einfach zusammengewürfelt wurden.

\paragraph{Externe Konsistenz}
Externe Konsistenz bezieht sich auf Konsistenz mit anderen Elementen in der Umgebung. Die Vorteile der Internen Konsistenz werden hierbei systemübergreifend erweitert. Das Erreichen externer Konsistenz gestaltet sich jedoch auch schwieriger, da unabhängige Systeme selten exakt gleiche Designstandards haben.

Nicht alle dieser Konsistenzstandards können oder sollten in allen Fällen angewendet werden. 
Es lässt sich jedoch festhalten das Elemente in einer logischen Gruppe immer ästhetisch und funktional konsistent sein sollten.
Insgesamt sollte ästhetische und funktionale Konsistenz, wann immer möglich berücksichtigt werden, da durch ästhetische Konsistenz bei der Einführung einmaliger Identitäten Wiedererkennung gewährleistet werden kann und funktionale Konsistenz aus den bereits genannten Gründen die Usability eines Systems erhöht.
Abschließend sollten Systeme immer eine interne Konsistenz aufweisen, sollten bereits Designstandards existieren, gilt es diese zu analysieren.\cite{Lidwell.2010}

\subsection*{Sichtbarkeit}

Das Prinzip der Sichtbarkeit besagt, dass Systeme benutzbarer sind wenn der aktuelle Status des Systems, mögliche Aktionen und deren Auswirkungen für den Nutzer deutlich erkennbar sind.
Es beruht auf der Erkenntnis, das Menschen schneller und besser Lösungswege finden wenn sie aus einer Reihe von Optionen auswählen können, anstatt sich selbstständig an alle Möglichkeiten aus dem Stegreif erinnern zu müssen\cite{Lidwell.2010}.
Das macht es zu dem wichtigsten Prinzip für hohe Usability in komplexen Systemen, jedoch auch zu dem, welches am meisten verletzt wird\cite{Norman.2016}.
Häufig wird versucht alle möglichen Optionen die ein System bietet sichtbar zu machen, was vor allem in komplexeren Systemen dazu führt das sie relevanten Optionen durch Informationsüberladung auf Seiten des Nutzers schwerer zu erreichen sind. 
Anstatt die Usabilty zu erhöhen wird also genau das Gegenteil erzielt.
Lösungen für diese Problemstellung sind beispielsweise eine Hierarchische Anordnung der Elemente oder Kontextsensitivität des Systems.
Bei der Hierarchischen Anordnung werden Funktionen und Informationen in logische Kategorien unterteilt und in übergeordneten Menüs versteckt, welche bei Bedarf ausgeklappt werden können. Ein Beispiel hierfür ist ein Dropdownmenü, wie man es von vielen Websites kennt.
In einem Kontextsensitiven System werden Aktionsmöglichkeiten und Informationen je nach aktuellem Status des Systems versteckt oder angezeigt. Beispielsweise bekommt man in einer Modellierungssoftware mit unterschiedlichen Elementen immer nur die Properties angezeigt die für das aktuell ausgewählte Element relevant sind, und nicht alle Properties die im gesamten System existieren\cite{Lidwell.2010}.

\subsection*{Affordanz}

Affordanz bezeichnet die Möglichkeiten mit einem Objekt zu interagieren. Beispielsweise kann eine Checkbox an und wieder abgewählt oder ein Schieberegler nach oben und unten geschoben werden.
Die sichtbare Affordanz bezeichnet die Eigenschaft das einem Objekt die Interaktionsmöglichkeiten bereits angesehen werden können, ohne mit ihm interagiert zu haben.
Sichtbare Affordanz ist vor allem in der User Interface Gestaltung wichtig, weil praktisch betrachtet alle Pixel auf einem Bildschirm anklickbar sind, jedoch in den meisten Fällen keine Aktion durch das klicken ausgelöst wird.
Deshalb ist es wichtig dem Nutzer durch das Aussehen der Element zu vermitteln ob diese, wenn sie geklickt werden eine Aktion auslösen, um dem Nutzer wahlloses Klicken durch das Interface zu ersparen, bis ein interaktives Objekt gefunden wird.
Solche Probleme können visuell gelöst werden, indem man Objekte im User Interface wie Objekte in der echten Welt aussehen lässt, also beispielsweise einen Button dreidimensional gestaltet.
Alternativ kann man beispielsweise alle anklickbaren Objekte etwas anders gestalten als den Rest der Objekte im Interface, um dem Nutzer zu vermitteln das hier eine Interaktion stattfinden kann\cite{Knight.2019c}.

\subsection*{Rückmeldung}

Eine der grundlegendsten Richtlinien um die Usability eines Systems zu erhöhen, ist es dem Nutzer immer eine Rückmeldung auf seine Aktionen zu geben.
Das bedeutet dem Nutzer immer den aktuellen Systemstatus anzuzeigen und wie seine Aktion vom System interpretiert wurde.
Eine Rückmeldung ist vor allem auch dann wichtig, wenn die gewünschte Aktion nicht erfolgreich vom System ausgeführt wurde
Durch fehlende Rückmeldungen kommt Misstrauen beim Nutzer auf, weil ihm nicht vermittelt wird ob auf seine Aktionen auch eine Reaktion des Systems erfolgt\cite{Knight.2019c}.
Dieses Problem tritt beispielsweise auf, wenn ein System lange braucht um eine Eingabe zu verarbeiten und es versäumt dies dem Nutzer mitzuteilen.
So ein Verhalten könnte zur fälschlichen Annahme führen das System wäre kaputt, oder dazu das der Nutzer beginnt neue Interaktionsmöglichkeiten anzuklicken.
Reagiert das System innerhalb 0.1 Sekunden, nimmt der Nutzer dies als sofortiges Feedback wahr und keine gesonderte Meldung ist nötig.
Bewegt sich die Reaktionszeit zwischen 0.1 und 1.0 Sekunden ist führ gewöhnlich auch keine besondere Rückmeldung vom System nötig, auch wenn der Nutzer hier bereits nicht mehr das Gefühl hat direkt mit den Daten zu interagieren, da eine kurze Verzögerung stattfindet.
Sobald die Wartezeit auf Seiten des Nutzer jedoch eine Sekunde überschreitet sollte sich der Cursor in eine Sanduhr oder ähnliches verwandeln und damit die Rückmeldung geben, dass das System beschäftigt ist.
Sollte die systemseitige Verarbeitung der Eingabe länger als 10 Sekunden dauern ist es ratsam die Ladeanzeige durch eine konkrete Fortschrittsleiste zu ersetzen\cite{Nielsen.1995?}.

\subsection*{Mapping}
Mapping bezeichnet die Beziehung  zwischen Bedienelementen und den Effekten den deren Aktivierung auslöst.
Wenn der Effekt den eine Nutzerinteraktion nach sich zieht, den Erwartungen des Nutzers entspricht, handelt es sich um gutes Mapping.
Die ist beispielsweise bei einem elektronisches Fensterheber der Fall. Wird hier der Hebel nach oben bewegt, hebt sich das Fenster, bewegt man den Hebel nach unten senkt es sich.
Gutes Mapping wird zum Großteil durch Ähnlichkeit, das Verhalten oder der Bedeutung innerhalb eines Layouts erreicht.
Entspricht beispielsweise das Layout von Herdplattenreglern der Anordnung der Platten wird gutes Mapping durch das Layout erzeugt, der bereits beschriebene Fensterheber arbeitet mit dem Verhalten, und die Tatsache das ein Notfallknopf rot eingefärbt wird ist darauf zurückzuführen das die meisten Menschen rot mit Gefahr oder dem Stopplicht einer Ampel assoziieren.
In jedem dieser Fälle macht die Ähnlichkeit es möglich den Effekt der Handlung vorherzusehen, und vereinfacht dadurch die Bedienung für den Nutzer.
Aktionsmöglichkeiten müssen so platziert werden das ihre Position und ihr Verhalten dem Layout und dem Verhalten den Anwendung angepasst sind. 
Außerdem sollte es vermieden werden durch eine identische Aktion verschiedene Reaktionen auszulösen\cite{Lidwell.2010}.

\subsection*{Einschränkungen}
Einschränkungen in einem System limitieren die Interaktionsmöglichkeiten für den Nutzer.
Wird beispielsweise ein Button ausgegraut, der im aktuellen Kontext ohnehin keine Aktion ausführen würde wird der Nutzer rein optisch daran gehindert eine nicht zielführender Aktion auszuführen.
Durchdachte Einschränkungen dieser Art machen ein Design einfacher nutzbar und reduziert deutlich die Wahrscheinlichkeit von Fehlschlägen während der Systeminteraktion \cite{Lidwell.2010}.

\paragraph{Physische Einschränkungen}
Physische Einschränkungen limitieren den Bereich in dem Aktionen ausgeführt werden können, indem sie Eingaben des Nutzers umwandeln oder umleiten.
Eine Art der Einschränkungen ist das konvertieren der Eingabe in lineare oder kurvenförmige Bewegung, wie es Beispielsweise bei der Interaktion mit einer Scrollbar der Fall ist.
Mithilfe von Achsen können wirkende Kräfte in Rotationsbewegungen umgewandelt werden, was eine Kontrolloberfläche mit unendlicher Größe auf einem kleinen Feld erzeugt, was am Beispiel der Computermaus gut zu erkennen ist.
Die Letzte Form der Einschränkung passiert über Barrieren, die die Eingabe verlangsamen, komplett ausbremsen oder umleiten. Die Einfassung eines Computerbildschirms beschränkt beispielsweise physisch die Interaktionsfläche für den Nutzer.
Allgemein sind Physische Einschränkungen nützlich um die Anzahl fehlerhafter Eingaben zu vermeiden, oder manche Eingaben erst gar nicht zu ermöglichen\cite{Norman.2016}.

\paragraph{Psychologische Einschränkungen}
Psychologische Einschränkungen limitieren die Anzahl möglicher Aktionen durch Nutzung des Wissens über das Verhalten und die Denkweise der Nutzer.
Dies passiert durch den Einsatz von Symbolen, nutzen bekannter Konventionen oder durch das bereits erwähnte Mapping.
Symbole sind sinnvoll um Dinge zu benennen, zu erklären oder auch um Warnungen visuell, auditiv oder fühlbar darzustellen.
Mit Konventionen macht man sich bekannte Interaktionsmöglichkeiten zunutze, weshalb sie sich gut eignen Systeme sowohl konsistent als auch leicht benutzbar zu machen.
Mappings sind, aus bereits erwähnten Gründen, nützliche um dem Benutzer zu vermitteln welche Aktionen aufgrund der Sichtbarkeit, Position oder dem Aussehen der Elemente möglich sind\cite{Norman.2016}.

Zusammenfassend sollten Einschränkungen im Allgemeinen verwendet werden um die Benutzbarkeit eines Systems zu vereinfachen und die Anzahl an Fehlern zu minimieren. Physische Einschränkungen dienen hierbei eher dem Verhindern ungewollter Eingaben oder gefährlicher Aktionen, Psychologische Einschränkungen sollen das Design eines Systems für den Nutzer klarer und intuitiver gestalten.

\subsection*{Vorteile für den Nutzer}
Durch das Befolgen der soeben erläuterten Gestaltprinzipien bei dem Entwurf eines User Interfaces, ist es möglich sich die Art und Weise wie Nutzer visuelle Reize verarbeiten zunutze zu machen um die Benutzerfreundlichkeit des Systems zu erhöhen.
Das passiert vor allem dadurch, dass man die kognitive Last des Nutzers verringern während er sich mit dem Interface auseinander setzt, indem man bereits bekannten Gestaltprinzipien nutzt.
Das bedeutet, dass der Nutzer seine Energie nicht darauf verschwenden muss darüber nachzudenken wie mit den Bestandteilen des Interfaces interagiert werden kann, oder was deren Funktionen sein könnten\cite{Knight.2019c}.

\section{EB Guide Studio}
Wie bereits in Abschnitt 1.2 erwähnt dient EB GUIDE der Entwicklung multimodalder HMIs.
Um nicht nur das Design sondern auch das Verhalten von User Interfaces bestimmen zu können und eine Auslieferung auf das Zielsystem zu ermöglichen besteht die Produktlinie EB GUIDE aus den verschiedenen, in \cref{fig:guide_puzzle} zu sehenden, Komponenten.
Hierbei wird zwischen Komponenten für das Graphical User Interface (GUI) und Komponenten für die Sprachsteuerung unterschieden.
Da die Sprachkomponenten jedoch für diese Arbeit nicht weiter relevant sind werden diese in den folgenden Kapiteln auch nicht genauer erläutert.
Innerhalb des GUI Bereiches bildet EB GUIDE Studio das tatsächliche Modellierungstool mit dem das Verhalten und Aussehen der Benutzeroberfläche definiert wird.
Für das entwickelte Modell stellt das EB GUIDE Target Framework auf dem Zielsystem die Laufzeitumgebung bereit.\cite{.c} 

\begin{figure} [!h]
\begin{center}
  \includegraphics[scale=0.7]{figures/EB_GUIDE_Puzzle.png}
  \caption{Aufbau EB GUIDE}
  \label{fig:guide_puzzle}
\end{center}
\end{figure}

EB Guide Studio ist das Interface von EB Guide mit dem nach dem What-You-See-Is-What-You-Get (WYSIWYG) Prinzip User Interfaces modelliert werden. 
Durch das WYSIWYG Prinzip ist es während des Modellierens einer View bereits möglich das Endergebnis des Designs zu sehen.
Das Verhalten des Interfaces hingegen wird mithilfe einer Zustandsmaschine, der sogenannten Statemachine, modelliert die auf dem UML- Prinzip aufbaut.
Die Trennung der Logik und des Designs wird in EB GUIDE Studio grafisch durch zwei unterschiedliche Arbeitsoberflächen gestaltet in welchen den Modellierern jeweils die entsprechenden Tools und Elemente zur Verfügung stehen.

\begin{figure} [!h]
\begin{center}
  \includegraphics[scale=0.4]{figures/Guide_Statemachine.PNG}
  \caption{EB Guide Studio Statemachine}
  \label{fig:Guide_Statemachine}
\end{center}
\end{figure}

In \cref{fig:Guide_Statemachine} ist die Statemachine für ein simples Beispiel zu sehen.
Links neben der Arbeitsfläche befindet sich eine Toolbox mit deren Inhalt per Drag and Drop auf der Arbeitsfläche die benötigte Logik definiert wird.
Wie bei UML-Diagrammen gibt es einen Initial State der den Startpunkt angibt und einen Final State der die Statemachine beendet.
Die ebenfalls zu sehenden View States stehen für einen Screen im Endprodukt, dementsprechend wird in den View States auch das Aussehen der Interfaces definiert.
Die Verbindungen zwischen den States werden als Transitionen bezeichnet und mithilfe von Events ausgelöst.
Events stellen hierbei beliebige Ereignisse dar die durch Elemente in der View ausgelöst werden können.
Der Auslöser für das Event wird mithilfe einer eigens für EB Guide entwickelten Skriptsprache als Trigger für dieses gesetzt.
Die häufigsten Auslöser sind Benutzeraktionen mit Widgets, die in \cref{fig:Guide_View}zu sehen sind.
Widgets sind Elemente mit denen das Aussehen des Interfaces im sogenannten View Editor bestimmt wird und die sich in Basis- und 3D-Widgets einteilen lassen.
Alle Basiswidgets verfügen über Basiseigenschaften wie Höhe, Breite und Farbe sowie über spezifische Eigenschaften wie zum Beispiel "Touch-Released" bei einem Button.\cite{studio_guide}
Beipspielsweise wird das Event "RectangleClick", was sich in \cref{fig:Guide_Statemachine} an der Transition zwischen View State 1 und View State 2 befindet in diesem Beispiel durch das Klicken auf das grüne Rechteck in View State 1 ausgelöst.
Ist die Benutzeraktion abgeschlossen findet der Übergang von View State1 zu View State 2 statt und der Nutzer sieht nun anstatt dem grünen ein rotes Rechteck.
Damit diese Aktion erfolgreich ausgeführt wird muss das grüne Rechteck die Eigenschaft "Touch-Released"\ zugewiesen bekommen und über die EB Guide Skriptsprache mitgeteilt bekommen das Event RectangleClick zu feuern sobald das grüne Rechteck berührt wurde.
Da sich dieses Event in der Statemachine an der Transition zwischen den beiden States befindet wird nun durch einen Klick auf das grüne Rechteck ein Bildschirmwechsel zwischen den beiden View States ausgelöst.

\begin{figure}[!h]
\begin{center}
  \includegraphics[scale=0.4]{figures/Guide_View.PNG}
  \caption{EB Guide VIEW}
  \label{fig:Guide_View}
\end{center}
\end{figure}


