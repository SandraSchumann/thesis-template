\chapter{Usability Test}\label{ch:outlook}

Aufbauend auf allen bisher getätigten Analysen und Anpassungen des Interfaces, gilt es abschließend noch den Prototypen und die Implementierung mithilfe eines Usability Tests zu evaluieren.
Hierbei wird im Schritt \glqq Finalize the UX design\grqq{} des Human-Centered Design Process die Rolle des Usability Testers abgedeckt, auf weitere Anpassungen des Interfaces in der Funktion des User Interface Designers wird verzichtet.

In diesem abschließenden Kapitel werden die Grundlagen des verwendeten Tools für den Usability Test erläutert.
Darauf folgend wird die Art des durchgeführten Tests definiert und dargelegt auf welchen Grundlagen diese Wahl getätigt wurde.
Aufbauend auf den theoretischen Erläuterung wird die letztendliche Testaufgabe konkret definiert und die nötigen Anweisungen, sowie die Materialien zur Auswertung der Tests erstellt.
Abschließend werden die Ergebnisse der durchgeführten Auswertungen der Tests dargestellt und interpretiert, bevor es noch einen Ausblick auf das mögliche weitere Vorgehen gibt.

\section{Lookback}

Bei Lookback handelt es sich um eine Cloudbasierte Softwarelösung, die es ermöglicht User Experience geräteübergreifend zu dokumentieren.
Bei der Durchführung der Tests besteht die Möglichkeit als Tester aktiv teilzunehmen, oder die Probanden unmoderiert mit dem Prototyp oder der Software interagieren zu lassen.
Möchte der Usability Tester jedoch teilnehmen kann hier aus den beiden Möglichkeiten gewählt werden, sich mit dem Nutzer innerhalb einer Live-Session oder  persönlich vor Ort an einem Rechner zu treffen.

Für die durchzuführenden Tests erstellt der Usability Tester innerhalb von Looback ein Projekt.
Zugunsten des Datenschutzes besteht hier die Möglichkeit die Projekte auf privat zu setzen und nur ausgewählten Personen des Teams Zugriff zu den Aufnahmen zu gewähren.
Innerhalb des Projekteinstellungen können Instruktionen für die Nutzer bereit gestellt werden, die während des Test erscheinen und ihn durch die Aufgaben führen.
Das ist vor allem dann hilfreich, wenn die Testperson den Test autonom durchführen soll.

Sollte der Test nicht gemeinsam in einem Raum stattfinden kann mithilfe eines Links der Test mit den Probanden geteilt werden, und der Tester bekommt eine Benachrichtigung sobald der Proband bereit ist oder mit der autonomen Durchführung begonnen hat.
Während der Session hat der Tester die Möglichkeit mit Zeitstempel versehene Notizen zu machen oder mit eventuell teilnehmenden Teamkollegen zu chatten.
Diese Möglichkeit der Live\-Dokumentation erleichtert die darauffolgende Auswertung des Test ungemein, da man sofort Auffälligkeiten festhalten kann und diese in der Aufzeichnung dadurch leichter auffindbar sind.
Nach Abschluss des Tests speichert Looback die Aufnahme in der Cloud, wodurch diese für die nachträgliche Auswertung des Tests abrufbar bleibt. \cite{.10.01.2020}

Die Möglichkeit der Live\-Dokumentation bildet das ausschlaggebende Argument für die Wahl des Tools, ebenfalls besteht die Möglichkeit in der hochgeladenen Aufnahme Kommentare hinzuzufügen, was die Auswertung sehr erleichtert.
Zusätzlich ist es wichtig den Test online durchführen zu können, da viele Modellierer nicht am Hauptstandort von EB beschäftigt sind, wodurch persönliches Testen nicht immer möglich ist.

\section{Remote Usability Test}
Die im vorherigen Kapitel schon bereits kurz benannten In Person Tests finden in der Regel in einem Usability Labor statt.
Dies bezeichnet einen abgeschlossener Raum ohne Störungsquelle, der mit aller benötigte Hard- und Software ausgestattet ist und in dem sich nur der Proband und der durchführende Tester aufhalten.

Bei einem Remote Usability Test wird die Arbeitsaufgabe nicht gemeinsam im Labor, sondern räumlich getrennt durchgeführt.
Hier lässt sich noch zwischen in Asynchronen und Synchronen Tests unterscheiden.
Bei letzteren besteht, trotz der räumlichen Trennung, eine direkte Verbindung mithilfe von Webcam und Sprachanruf, zwischen Tester und Proband.
Gleichzeitig dazu wird der Bildschirminhalt der Testperson übertragen, um es dem Tester zu ermöglichen dessen Interaktionen  zu verfolgen und durch den Test führen zu können.
Durch diese direkte Verbindung ist es ebenfalls möglich während, oder unmittelbar nach dem Test Fragen zu stellen.
Bei synchronen Tests besteht der Vorteil darin, mit geringem Aufwand sehr weit verteilte Nutzergruppen in den Test einbinden zu können.
Zusätzlich dazu findet der Test in der gewohnten Umgebung des Nutzers statt, es wird also keine ungewohnte Situation in einem Labor geschaffen, was die Nervosität der Nutzer eventuell steigern könnte.
Auch können die Probanden hier mit ihrer gewohnten Hard- und Software arbeiten, was vor allem für repräsentative Werte die die Effizienz betreffen von Vorteil ist.
Durch den Umstand der gewohnten Arbeitsumgebung entsteht jedoch in vielen Fällen auch ein technische Zusatzaufwand auf Seiten des Nutzers.
So kann es beispielsweise nötig werden sich Headset und Webcam anzuschaffen, oder zusätzliche Software auf dem Arbeitsgerät installieren zu müssen.
Dies tritt in einem Usability Labor nie auf, da hier eine einmalige Einrichtung der benötigten Hard- und Software stattfindet die exakt au den geplanten Test ausgelegt ist.

Im Rahmen eines asynchronen Tests besteht zusätzlich zu der räumlichen, auch noch eine zeitliche Trennung von Proband und Tester.
Identisch zum synchronen Test werden hier Gesicht und Bildschirminhalt der Testperson aufgezeichnet, der Nutzer kann jedoch aufgrund der Unabhängigkeit den Test zu einer ihm passenden Zeit durchführen.
Da er dadurch jedoch auch auf sich allein gestellt ist, empfiehlt es sich zusätzliche Kommentare und Fragebögen in den Test einzubauen um die direkte Befragung und Hilfestellung des synchronen Tests zu ersetzen.
Wie bei der synchronen Variante betseht hier der Vorteil das mit geringem Aufwand großräumig verteilte Nutzergruppen eingebunden werden können.
Zusätzlich können durch die vollautomatische Erfassung in dieser Variante auch sehr große Nutzergruppen effizient evaluiert werden.
Allerdings einstehen durch die zeitliche Trennung die NAchteile, das abgesehen von der Aufnahme keine Beobachtungsdaten existieren.
Es kann also beispielsweise nicht darum gebeten werden etwas genauer zu erläutern oder einen anderen Lösungsweg zu versuchen.
Die wohl größte Problematik bildet jedoch die Tatsache, dass nicht auf unerwartete Handlungen des Nutzers reagiert werden kann, was vor allem bei nur teilweise funktionalen Prototypen fatal sein kann.
Versuchen die Probanden hier einen Lösungsweg einzuschlagen, der in der vorliegenden Softwareversion nicht implementiert ist und auch nicht bedachte wurde, bekommt die Testperson eventuell auf keine Art und Weise eine Rückmeldung des Systems.
Diese Tatsache kann ohne weitere Unterstützung durch den Tester eventuell zum Abbruch des Test führen, was zu Unzufriedenheit auf Seiten des Testers und Nutzers führt.\cite{Sarodnick.2016}

Da Lookback jeden der eben erläuterten Tests unterstützt, wirkt sich das Tool auch nicht einschränkend aus und die Wahl kann aufgrund tatsächlich relevanter Tatsachen getroffen werden.
Aufgrund der Tatsache das innerhalb der Testaufgabe mit einem Prototyp interagiert werden muss, ist ein synchroner Test dem asynchronen vorzuziehen.
Da nicht alle in Guide zur Verfügung stehenden Interaktionsmöglichkeiten simuliert, und die Funktion \glqq publish to template interface\grqq{} verlagert wurde ist es wahrscheinlich, dass die Probanden an gewissen Punkten Unterstützung benötigen.
Es ist auch zu erwarten das bei den neuen Funktionen Fragen bei den Testpersonen auftauchen werden, die nicht alle in der Arbeitsaufgabe beantwortet werden können.
Im Gegensatz dazu wird auch Tester einige Aktionen genauer hinterfragen wollen oder herausfinden wollen warum gewisse Aktionen nicht durchgeführt wurden.

Grundlegend ist ein Test im Usability Labor, aufgrund der Ungestörtheit, immer dem Remote Test vorzuziehen.
Zum einen erstreckt sich die Nutzergruppe für diese Arbeit  jedoch über mehrere Firmenstandorte von Elektrobit, weshalb es nicht möglich ist den Test mit allen Probanden in einem Labor durchzuführen.
Zum anderen soll mithilfe Tests überprüft werden ob eine Effizienzsteigerung erzielt werden konnte.
Die Ausstattung in den Laboren entspricht nie hundertprozentig der gewohnten Umgebung, weshalb hier auch langsamere Leistungen aufgrund der fremden Hardware erbracht werden können.
Es wäre möglich die Tests mit einem Teil der Probanden im Labor und mit dem anderen Remote durchzuführen, um die Ergebnisse jedoch so gut vergleichbar wie möglich zu halten werden alle Untersuchungen unter den gleichen Bedingungen in einem Remote Test durchgeführt.

\section{Arbeitsaufgaben}

Um in der abschließenden Arbeitsaufgabe alle Änderungen testen zu können ist es nötig sich an den ursprünglich analysierten Benutzeranforderungen zu orientieren, auf deren Grundlage die Änderungen entworfen und der Prototyp gebaut wurde.
Daher werden zu den in Kapitel 3.0.3. bereits formulierten qualitativen Anforderungen nun noch die, im Rahmen eines Tests messbaren, quantitative Nutzeranforderungen für die ausgewählten Anpassungen ergänzt.

\textbf{Quantitative Benutzeranforderung für Template Properties}\newline
\textbf{Messung der Effizienz:}
Nutzer, die die Funktion \glqq publish to template interface\grqq{} über einen Linksklick auf den Kreis ausführen, sollen messbar schneller sein, als Nutzer die dies über einen Rechtsklick auf das Quadrat tun. \newline
\textbf{Messung der Fehlerrate:} 
Nutzer, die die Funktion \glqq publish to template interface\grqq{} über einen Linksklick auf den Kreis ausführen, sollen eine niedrigerer Fehlerrate aufweisen, als Nutzer die dies über einen Rechtsklick auf das Quadrat tun.

\textbf{Quantitative Benutzeranforderung für Widget Feature Properties} \newline
\textbf{Messung der Effizienz:}
Nutzer, die die Filterfunktion nutzen, sollen schneller ihr gewünschtes Widget Feature Property finden als Nutzer die dies händische suchen müssen. \newline
\textbf{Messung der Fehlerrate:}
Bei Nutzern, die die Filterfunktion nutzen soll die Fehlerrate sich bei der Suche nach dem gewünschten Widget Feature Property auf auf 0 reduzieren.

\textbf{Quantitative Benutzeranforderung für Mehrfachselektion}\newline
\textbf{Messung der Effizienz:}
Nutzer die mehrere Objekte gleichzeitig selektiert haben, sollen deren korrekte Positionierung  und Skalierung schneller abgeschlossen haben, als Nutzer die keine Mehrfachselektion benutzen.\newline
\textbf{Messung der Fehlerrate:}
Nutzer, die Objekte mithilfe der Mehrfachselektion skalieren oder positionieren, sollen diesen Vorgang mit einer geringeren Fehlerrate abschließen, als Nutzer die keine Mehrfachselektion nutzen.
Zusätzlich wird hier darauf geachtet inwiefern die Ergänzungen genutzt werden, vor allem die neu eingeführten \glqq Alignment Actions\grqq{} und die Funktion \glqq Insert in Template\grqq{} und welche Verbesserungen hier noch einzubringen sind.

Aus den aufgeführten Benutzeranforderungen lassen sich wiederum Subtask ableiten, anhand deren überprüft werden kann welche Interaktionen von Seiten des Nutzers in welcher Zeitspanne abgeschlossen werden, an welcher Stelle Fehler auftreten und welche Möglichkeiten nicht genutzt werden.
Hierfür ist es notwendig jede Interaktion in kleine Subtasks zu untergliedern um beispielsweise genau die Stelle festzustellen zu können an der die Interaktion mit dem Interface zu Fehlern führt.
Bei der Filterung der Feature Widget Properties kann dies eventuell schon daran scheitern das nicht in das Texteingabefeld geklickt wird, oder auch erst durch die Eingabe eines falschen Filterbegriffes.
Die formulierten Subtasks für den in dieser Arbeit durchgeführten Test lassen sich in Anhang \ref{app:Subtasks} nachvollziehen.

\begin{center}
  \includegraphics[width=\textwidth]{figures/Styleguide_Rahmen.png}
  \captionof{figure}{Styleguide}
  \label{fig:Styleguide}
\end{center}

Auf Grundlage dieser Subtasks beurteilt, scheint es weiterhin sinnvoll den Testpersonen die Modellierung einen Startscreens für ein Human Machine Interface der Automobilbranche als Testaufgabe ausführen zu lassen.
Hierfür ist es notwendig einen grafischen Styleguide zu erstellen an dem sich die Nutzer wie aus ihrer täglichen Arbeit gewohnt orientieren können.
Darüber hinaus ist es auch für Evaluierung der Tests notwendig die Nutzer die exakt gleichen Aufgaben durchführen zu lassen.
Der in \cref{fig:Styleguide} zu sehende Styleguide zeigt einen Startscreen mit drei Bildern und Bildunterschriften im Hauptmenü und zwei Bildern in der Fast-Access-Leiste.
Für jedes dieser Elemente sind die für den Modellierer relevanten Properties sichtbar, sowie bei den Bildern die Namen wie sie auch in den Assets von EB GUIDE auftauchen.
Diese Anmerkungen sind innerhalb des Styleguides alle in pink gehalten um sie deutlich vom tatsächlichen Design abzugrenzen, wobei die Rahmen für das Hauptmenü und die Fast-Access Leiste ebenfalls der Orientierung dienen und zum Verständnis der im folgenden beschriebenen Arbeitsaufgabe notwendig sind.

Zusätzliche zu dieser grafischen Darstellung der Arbeitsaufgabe, wird noch eine textuelle Angabe erstellt, die zur Durchführung des Tests nötig ist.
Es werden insgesamt drei verschiedene Angaben erstellt, die in den Anhängen \ref{app:Aufgabe_Filter}, \ref{app:Aufgabe_Prototyp} und \ref{app:Aufgabe_Guide} zu finden sind.
Die ersten beiden dienen hierbei der Überprüfungen der Anpassungen.
Da ein Teil hiervon implementiert und der andere Teil mithilfe eines Prototypen umgesetzt wurde ist es hier nötig den Test in zwei Teile aufzuspalten, weshalb auch zwei getrennte Angaben existieren.
In Testaufgabe \ref{app:Aufgabe_Filter} galt es den implementierten Filter zu überprüfen, weshalb die Nutzer hier aufgefordert werden die drei Bilder für das Hauptmenü zu platzieren und mit Widget Feature Properties zu versehen.
Für diesen ersten Teil wird den Nutzern ein vorbereitetes Projekt mit den benötigten Assets zur Verfügung gestellt, um zu gewährleisten das alle mit einer identischen Ausgangssituation starten.
Es wird hier explizit nicht auf die implementierte Änderungen hingewiesen, da überprüft werden soll ob diese von den Nutzern intuitiv benutzt wird.
Um jedoch zu gewährleisten, dass jeder Nutzer das Filterfeld theoretisch nutzen könnte wird darum geben die Bilder mit Widget Feature Properties zu versehen.

Für Aufgabe \ref{app:Aufgabe_Prototyp} ist es notwendig den Übergang zu der Aufgabe innerhalb des Prototyp so nahtlos wie möglich zu gestalten und gleichzeitig wieder eine identische Ausgangssituation für alle Nutzer zu schaffen.
Das initiale Aussehen des Prototyp beinhaltet deshalb bereits die die drei bereits eingefügten Bilder im Hauptmenü, entspricht also der Situation mit der das vorherige Projekt in Guide von den Testpersonen verlassen wurde.
Da die Multiselektion eine Neuerung ist die eher unwahrscheinlich selbstständig von den Nutzern entdeckt wird, wird hier zu Anfang darauf hingewiesen das der vorliegende Prototyp Multiselektion unterstützt.
Mithilfe der Fast-Access Leiste, welche mithilfe von Templates modelliert werden soll, wird die Verlagerung der Funktion \glqq publish to template interface\grqq{} überprüft.
Ebenfalls wird in diesem Zug darauf hingewiesen, das nun auch die Bilder mithilfe von Multiselektion in Templates eingefügt werden können, jedoch ohne genaue Erklärung auf welche Art und Weise das funktioniert.
Abschließend sollen noch die Bilder und Labels positioniert und skaliert werden.
Es wird hier nocht noch einmal explizit auf die Multiselektion verwiesen, da herausgefunden werden soll inwiefern die Probanden dies nach der Information zu Anfang der Angabe intuitiv für die restliche Aufgabe nutzen.

Die letzte Aufgabe \ref{app:Aufgabe_Guide} dient zur Erlangung der Vergleichswerte für die Effizienz und wird deshalb in der unmodifizierten Version von Guide umgesetzt.
Da hier deshalb kein Übergang in den Prototyp notwendig ist ist eine zusammenhängende Arbeitsaufgabe ausreichend.
Die Probanden müssen hier die identische Aufgabe durchführen und werden, angepasst an die beiden vorherigen Angaben, in der Nutzung von Templates eingeschränkt oder dazu aufgefordert.
Den Nutzern hier ein komplett freies Arbeiten ist nicht möglich, da möglichst identische Arbeitsschritte getätigt werden müssen um einen validen Vergleich anstellen zu können.

\section {Ergebnisse}
Die Anzahl der in einem Test gefunden Usabilityprobleme lässt sich laut Nielsen und Landauer nach folgender Formel berechnen.

\begin{center}
$\mathbf{N (1-(1- L ) n )}$ 
\end{center}

wobei N der kompletten Anzahl der Usabilityprobleme im System entspricht und L der Anzahl der entdeckten Probleme nach dem Test mit einem Nutzer.
L entspricht hier im Durchschnitt 31\%, was zu der folgenden Grafik führt.  \cite{Nielsen.1993}

\begin{center}
  \includegraphics[width=0.7\linewidth]{figures/curve1.png}
  \captionof{figure}{Aufdeckungsrate von Usabilityproblemen (nach \cite{.h})}
  \label{fig:curve}
\end{center}

Bei Betrachtung von \ref{fig:curve} wird deutlich dass, solange mit keinem Nutzer getestet wurde, es auch keinen Aufschluss über die Usability Probleme eines Systems gibt.
Sobald Daten mithilfe eines Nutzers gesammelt wurden werden bereits 25\% der Schwächen aufgedeckt, wird der Test mit einem zweiten Nutzer durchgeführt decken sich bereits einige der Entdeckungen, es werden aber noch durchaus noch neue Schwächen entdeckt und unterschiedliche Messergebnisse treten auf.
Je mehr Nutzer untersucht werden, desto häufiger decken sich die Beobachtungen und Messungen mit den Ergebnissen der bereits untersuchten Nutzer.\cite{.h}
Entgegen einer häufigen Annahme ist es also nicht unbedingt sinnvoll einen Usability Test mit einer möglichst großen Zahl an Testpersonen durchzuführen, da der Tester ab einem gewissen Punkt fast ausschließlich die gleichen Probleme sehen und Messwerte erhalten wird.
Neue Informationen erhält man meist maximal bis zur Untersuchung des fünften Nutzers, weshalb dies auch die optimale Anzahl an Probanden darstellt.

Wird nun aber, wie im Falle dieser Arbeit, eines der messbaren Usabilityattribute verglichen ist es nötig die Anzahl der Nutzer zu verdoppeln.
Es werden zwei verschiedene Versionen eines Systems verglichen, die jeweils von fünf Nutzer getestet werden.
Dadurch werden bei jedem System etwa 80\% oder 90\% der Schwächen aufgedeckt, und bei der Messung der Attribute Effizienz und Fehlerrate kann ein repräsentativer Mittelwert gebildet werden.

Alternativ gäbe es die Möglichkeit den Test mit nur fünf Nutzern durchzuführen, was den Vorteil ergeben würde die Messwerte einer Person bei dem alten und neuen Interface zu vergleichen.
Allerdings würde hier die Problematik entstehen das der Nutzer die gleiche Arbeitsaufgabe doppelt durchführen würde, was zu einer Verfälschung der Ergebnisse führt, da die Angaben und Koordinaten der Objekte bereits bekannt sind.
Die Durchführung der identischen Arbeitsaufgabe ist jedoch dringend notwendig um vergleichbare Werte zu erhalten.
Aus diesem Grund bevorzugt Nielsen auch die Messung mit der doppelten Anzahl an Probanden, statt Nutzern zweimal die gleiche Aufgabe durchführen zu lassen.\cite{.h}

Die im Folgenden dargestellten Ergebnisse wurden durch das Testen einer Gruppe aus zehn Personen erzeugt, die aus sechs Expertennutzern und vier Gelegenheitsnutzern besteht.
Zwar wäre eine 1:1 Zusammensetzung der Gruppe der Testpersonen wünschenswerter, firmenintern standen jedoch zum Zeitpunkt der Messung nicht mehr Personen zur Verfügung, weshalb es einen Expertennutzer mehr in der Testgruppe gibt.
Die Einstufung als Expertennutzers wird dadurch definiert das die Person aktuell aktiv in einem Projekt mit EB Guide 6 arbeitet und dies auch schon seit mindestens 2 Monaten ununterbrochen tut.
Gelegenheitsnutzer sind all diejenigen, die zwischen dem Nutzen der Software immer mindestens 2 Wochen pausieren und eine einführende Schulung erfolgreich abgeschlossen haben.
Die Einstufung als Expertennutzers wird dadurch definiert das die Person aktuell aktiv in einem Projekt mit EB Guide 6 arbeitet und dies auch schon seit mindestens 2 Monaten aktiv tut.
Aus den gemessenen Werten wird jeweils ein Mittelwert gebildet, zusätzlich wird bei den Neuerungen untersucht welcher der möglichen Wege zur Problemlösung genutzt wird und welcher nicht.
Über die Fehlerrate kann ergänzend aufgedeckt werden ob noch Verbesserungen am Design vorgenommen werden müssen.

\subsection{Ergebnisse überarbeitetes Interface}
Der Prototyp und der implementierte Filter werden demnach mit fünf Probanden getestet, welche sich aus drei Experten und zwei Gelegenheitsnutzern zusammensetzen.
Nach der Durchführung der Aufgabe werden den Nutzern noch zusätzliche Fragen zu ihrem Verhalten gestellt, welche in der Folgenden Auswertung ebenfalls aufgeführt werden.

\paragraph{Widget Feature Properties}
Der Filter wird von drei Probanden genutzt, die anderen beiden, jeweils ein Experte und ein Gelegenheitsnutzer, geben anschließend an die Funktion nicht gesehen zu haben.
Ein Nutzer wendet den Filter erst dann an, nachdem er zwei Menüs auf der Suche nach dem richtigen Feature erfolglos ausgeklappt hat.
Er und die Anderen beiden geben anschließend an den Filter nicht als Neuerung wahrgenommen zu haben, ihn jedoch intuitiv genutzt zu haben.

Die Auswahl eine Feature Properties dauert mithilfe des Filters durchschnittlich 2 Sekunden.
Zwei der Nutzer erzeugen eine Fehlerrate von 2 Fehlern bei der Auswahl.
Aus der Suche nach dem Scale Mode filtern die Probanden mit dem Wort \glqq Scal\grqq{}.
Dadurch taucht, wie in \ref{fig:Feature_Test} zu sehen, in der Ergebnissen zusätzlich zu dem Scale Mode das Feature Scaling auf, welches dann fälschlicherweise ausgewählt wird.

\begin{center}
  \includegraphics[scale= 0.6]{figures/Feature_Test.PNG}
  \captionof{figure}{Filterung nach Scale Mode}
  \label{fig:Feature_Test}
\end{center}

\paragraph{Publish to template interface}
Die Verlegung des Hotspots für die Funktion \glqq publish to template interface\grqq{} wird ebenfalls von drei der fünf Probanden selbstständig gefunden, die alle benötigen Properties dadurch in durchschnittlich 4,6 sek publishen können.
Die neue Position wird von einem Experten und einem Gelegenheitsnutzer nicht entdeckt, jedoch nach Aufklärung von Seiten des Testers als nützlicher Shortcut eingestuft.
Bei den nötigen Klicks für die das publishen der Objekteigenschaften wird eine Fehlerrate von 0 erzielt.

\paragraph{Multiselektion}
Für die Skalierung der drei Bilder des Hauptmenüs nutzen alle Probanden die Multiselektion und schließen den Vorgang in durchschnittlich 7,2 Sekunden ab, wobei ihnen keine Fehler unterlaufen.

Bei den Labels haben nur vier Testpersonen die Multiselektion in durchschnittlich 8 Sekunden mit einer Fehlerrate von 0 genutzt, der fünfte Nutzer hat, nach eigenen Aussagen, aus Gewohnheit jeden Text einzeln positioniert obwohl vorher für die Bilder die Mehrfachselektion verwendet wurde.

Bei der Positionierung muss unterschieden werden ob die Arbeitsaufgabe mithilfe der Alignment Actions oder mit einfacher Multiselektion gelöst wurde.

Ein Proband macht bei den Bildern Gebrauch von den Alignment Actions und schließt die Positionierung aller drei Bilder in 5 Sekunden ab.
Allerdings lässt sich hier eine Fehlerquelle beobachten.
Der Nutzer legt zuerst den Abstand zwischen den Objekten fest, vergisst jedoch das Ankerbild an dem sich die anderen Bilder ausrichten an die richtige Position zu setzen.
Nachdem dieses korrekt positioniert ist muss die Ausrichtung erneut durchgeführt werden.
Drei der Anderen Nutzer haben die Alignment Actions bei den Bildern nicht gesehen, ein vierter hat sie zwar wahrgenommen, hatte zu diesem Zeitpunkt die Bilder jedoch einzeln schon so korrekt positioniert das er von der Nutzung abgesehen hat.

Bei den Labels nutzt dieser Proband die Alignment Actions, ebenso die Testperson die diese Funktion auch bei den Bildern angewandt hat.
Dadurch kann die Positionierung hier in durchschnittlich 6 Sekunden abgeschlossen werden, es tritt jedoch ein identischer Fehler mit dem Ankerobjekt auf, was hier ebenfalls eine Fehlerrate von 1 ergibt.
Die Probanden die diese Funktion nicht nutzten geben hierfür die gleichen Gründe an wie bei den Bildern.

Zusätzlich gäbe es bei den Texten die Möglichkeit diese mithilfe der Alignment Actions an den Bildern auszurichten.
Auf die Idee ein Bild und den dazugehörigen Text gleichzeitig auszuwählen kommt jedoch keine der Testpersonen, was darauf zurückzuführen ist, dass sich erst noch an die neuen Funktionen gewöhnt werden muss und die gleichzeitige Auswahl verschiedener Objekte zum aktuellen Zeitpunkt noch zu verwirrend ist.

Die Positionierung über normale Multiselektion wird bei den Bildern von vier Nutzern durchgeführt, wobei die identischen y-Koordinaten zusammen angepasst werden und danach die x-Koordinate für jedes Bild einzeln.
Mit diesem Vorgehen ist die Positionierung in durchschnittlich 3,5 Sekunden abgeschlossen und es werden zusätzlich keine Fehler gemessen.

Bei den Texten ist das Vorgehen für die Positionierung identisch, es treten ebenfalls keine Fehler auf und die durchschnittliche Zeitspanne beträgt 4,6 Sekunden.

Die Funktion \glqq Insert in Template\grqq{} wird von keinem der Nutzer entdeckt. Bei der abschließenden Befragung geben auch alle Probanden an, dass sie diese Funktion als nicht sinnvoll erachten.

\subsection{Ergebnisse altes Interface}
Um die Vergleichswerte zu erhalten wurde die Testaufgabe mit dem bestehenden Interface ebenfalls mit fünf Personen durchgeführt.
Die Zusammensetzung aus drei Experten und zwei Gelegenheitsnutzern ist hier identisch zur Testgruppe des Prototypen.

\paragraph{Widget Feature Properties}
Da hier keine Filterfunktion zur Verfügung steht treten hier, wie zu erwarten, mehr Fehler bei den Nutzern auf.
Von den fünf Probanden begehen zwei Nutzer 2 Fehler und ein Nutzer 3 Fehler.
Die restlichen beiden Testpersonen finden das gewünschte Feature auf Anhieb, müssen hier jedoch auch einige Sekunde überlegen, weshalb bis zu Wahl des gewünschten Properties durchschnittlich 8,8 Sekunden brauchen.

\paragraph{Publish to template interface}
Die Funktion \glqq publish to template interface\grqq{} wird in der aktuellen Version von den Probanden in durchschnittlich 16 Sekunden abgeschlossen.
Eine Person erzeugt hier eine Fehlerrate von 1 indem sie nach dem Rechtsklick auf das Rechteck hinter dem zu verlinkenden Propertie zuerst die falsche Funktion auswählt.
Bei allen anderen Probanden lässt sich ebenfalls beobachten das sie kurz überlegen welche der in \ref{fig:Template} zu sehenden Alternativen ausgewählt werden muss.
\begin{center}
  \includegraphics[scale= 0.8]{figures/Template.PNG}
  \captionof{figure}{Auswahlmöglichkeiten nach Rechtsklick auf Templateproperties }
  \label{fig:Template}
\end{center}

\paragraph{Positionieren/Skalieren ohne Multiselektion}
Das Skalieren und Positionieren der Texte und Bilder wird in der aktuellen Guideversion von den Nutzern meist so gelöst das ein Bild mit allen nötigen Features ausgestattet und dieses dann kopiert wird.
Anschließend ist es nur noch nötig die unterschiedlichen Eigenschaften der Kopien entsprechend der Spezifikation anzupassen.

Da bei der Skalierung die Werte nach dem Kopieren nicht mehr verändert werden müssen kommen die Probanden hier auf eine durschnittliche Arbeitszeit von 4,8 Sekunden, in der der Kopiervorgang bereits einberechnet ist.
Fehler treten hier nur auf wenn die Probanden die Werte nicht händisch eingeben sondern mit dem etwas komplizierterem Ansatz der Datapoolitems arbeiten.
Hierbei werden die Eigenschaften wie Breite und Höhe mit einem Item verlinkt dessen Wert sich an einer Stelle zentral anpassen lässt und alle verlinkten Objekte entsprechend verändert.
Fehler treten hierbei durch Verlinkung des falschen Datapoolitems oder der Eingabe des falschen Wertes auf.
Die Anzahl bemisst sich in diesem Testfall auf 2 Fehler bei einem Probanden der diesen etwas komplizierteren Modellierungsansatz wählt.

Bei der Skalierung der Labels arbeitet keiner der Nutzer mit Datapoolitems, weshalb hier eine Fehlerrate von 0 erzeugt wird und dier Vorgang für alle Texte in durchschnittlich 9 Sekunden abgeschlossen ist.

Für die Positionierung der Bilder und Labels müssen die Eigenschaften der kopierten Elemente angepasst werden.
Dies geschieht für erstere in 8,5 Sekunden, bei den Labels dauert es durchschnittlich 10,8 Sekunden.
Hierbei tritt bei den Bildern ebenfalls wieder ein Fehler bei Arbeit mit den Datapoolitems auf, bei den Texten beläuft sich die Fehlerrate bei allen Nutzern auf 0.

\subsection{Vergleich und Interpretation}
Auf Grundlage der gemessenen Daten kann nun ein direkter Vergleich zwischen dem bestehenden und dem überarbeiteten Interface von EB GUIDE getätigt werden.
Weiterhin können Beobachtungen über die Nutzung der Ergänzungen interpretiert werden und anhand der Messwerte evaluiert werden ob die definierten Quantitativen Benutzeranforderungen erfüllt wurden.

\paragraph{Widget Feature Properties}
Mithilfe des Filters gelingt es den Probanden deutlich schneller das gewünschte Feature Property zu finden, wodurch die Anforderung an die Effizienz erfüllt ist.
Die angestrebte Fehlerrate von 0 kann jedoch aktuell noch nicht erzielt werden.
Die Fehler können sich eventuell darauf zurückführen lassen das die Nutzer an die Übergeordneten Kategorien gewohnt sind und ihnen deshalb nicht bewusst war ob sie Scaling oder Scale Mode auswählen müssen.
Hier bestünde die Möglichkeit in einer weiteren Iteration zu testen ob sich die Fehleranzahl wieder verringert wenn die Kategorien während des Filterns eingeblendet bleiben.

\paragraph{Publish to template interface}
Die neue Position der Publish Funktion wurde zwar nicht von allen Nutzern selbstständig gefunden, wurde jedoch in Nachhinein von allen als sinnvoll eingestuft.
Die erreichte Fehlerrate von 0 stellt hier eine Verbesserung dar, da bei der jetzigen Implementierung teilweise falsche Optionen ausgewählt werden und die Nutzer lange überlegen müssen.
Zusätzlich schließen die Probanden ihr Vorgehen deutlich schneller ab, was sich auf den fehlenden Rechtsklick zurückführen lässt.
Damit sind beide Benutzeranforderungen für diese Funktion erfüllt.
Trotzdem kann die neue Position die Alte nicht in Gänze ersetzen, da es für Erstnutzer nicht möglich wäre die Funktion des Klicks zu erkennen.
Von daher bietet sich eine Kombination der bisherigen Implementierung und der Neuerung an.
Nutzer die sich der Funktion bewusst sind können den schnelleren Weg über Klick auf den Kreis wählen, Modellierer die sich noch mit der Funktionsweise von Guide vertraut machen können die bisherige Variante mit dem erklärenden Text wählen.

\paragraph{Multiselektion}
Die Funktion  \glqq Insert in Template\grqq{} wurde von keinem der Probanden benutzt und auch bei einer nachträglichen Befragung als nicht hilfreich eingestuft. 
Deshalb erscheint es hier sinnvoll diese Funktion nicht weiter zu verfolgen.

Die Alignment Actions beschleunigen die Positionierung der Bilder und der Texte, bringen jedoch aktuell noch eine höhere Fehlerrate mit sich als die bis jetzt übliche Art der Positionierung.
Die begangenen Fehler lassen sich jedoch auch darauf zurückführen das diese Funktion in GUIDE eine komplette neue und daher ungewohnte Ergänzung bietet.
Die neuen Funktionen müssen erst ausgetestet und verstanden werden, die falsche Ausführungsreihenfolge ist ein Fehler der vermutlich nur zu Anfang und nicht mehr bei regelmäßigem Gebrauch auftritt.
Diese Möglichkeiten zu erweitern und fortlaufen zu untersuchen  würde sich also lohnen.
Auch das Alignment von Text an Bildern sollte zumindest für eine weitere Iteration weiter verfolgt werden um herauszufinden ob die Nutzer, da sie nun von dieser Funktionalität wissen, diese eventuell auch benutzen.
Die Anforderung der höheren Effizienz wird durch die Alignment Actions also bereits erfüllt, in Bezug auf die Fehlerrate ist jedoch noch Nachbesserung erforderlich.

Die Positionierung der Elemente ohne Alignment Actions sondern nur mit Multiselektion hat innerhalb des durchgeführten Tests zeitlich am besten abgeschnitten, auch wurden hier keine Fehler durch den Nutzer begangen.
Die gleichzeitige Anpassung von Properties scheint also sowohl zeitlich sinnvoll, als auch für den Nutzer intuitiv zu verlaufen und erfüllt zudem die formulierten Benutzeranforderungen.

Bei der Skalierung der Bilder bietet die Multiselektion auf den ersten Blick keinen zeitlichen Vorteil.
Es gilt jedoch zu bedenken das im Testfall nur drei Bilder vorhanden waren, der Kopiervorgang dieser Bilder also kein großes zeitliches Gewicht hat.
Beinhaltet eine Spezifikation jedoch beispielsweise zehn statt nur drei Bilder geht durch den Kopiervorgang bereits viel mehr Zeit verloren.
Den Ansatz die Objekte zu kopieren und dann entsprechend anzupassen haben die Nutzer nur bei den Bildern, jedoch nicht bei den Texten verfolgt.
Deshalb sind hier die Messwerte innerhalb des Prototypen schneller als die in der bisherigen Version.
Da sich die Multiselektion für die Positionierung bereits als Mehrwert erwiesen hat, ist es sinnvoll die gleichzeitige Anpassung aller Properties bei Mehrfachselektion zu ermöglichen.
Es würde den Nutzer verwirren wenn nur gewisse Eigenschaften gleichzeitig anpassbar wären, weshalb es sinnvoll ist auch weiterhin die width und height der Objekte zusammen anpassen zu können.
In weiteren Iteration wäre es hier jedoch noch sinnvoll zu untersuchen ob bei größeren Projekten tatsächlich ein zeitlicher Mehrwert eintritt, da dies hier lediglich vermutet wird.
Die Benutzeranforderung sind in Bezug auf die Skalierung der Objekte dementsprechend noch nicht komplett erfüllt.
Die Fehlerrate beläuft sich zwar weiterhin auf 0, allerdings ist ein Mehrwert in Bezug auf die Effizienz noch nicht sicher gegeben.

\section {Ausblick}
Die vorliegenden Ergebnisse werden auf der Grundlage einer Iteration des Human Centered Design Process erlangt.
Je nachdem ob nach dieser Iteration die Benutzeranforderungen erfüllt sind ist es notwendig das Design anzupassen und nochmals zu evaluieren oder es als abgeschlossen zu betrachten und zur Implementierung überzugehen.

Wie im vorherigen Abschnitt bereits festgehalten erfüllt die Filterfunktion noch nicht alle Anforderungen, und bedarf in Bezug auf die Fehlerrate noch einer Nachbesserung.
Diese gilt es in einem weiteren Test erneut zu evaluieren.

Die neue Position der Funktion \glqq publish to template interface\grqq{} erfüllt alle definierten Bedingungen und kann nun deshalb zusätzlich zur bestehenden Funktion implementiert werden.

Die Funktionen der Multiselektion gilt es an diesem Punkt differenziert zu betrachten.
Da diese Ergänzung komplett neu in EB GUIDE sind gibt es hier noch viele Möglichkeiten und Funktionen die hinzugefügt und evaluiert werden können.
Das gleichzeitige Anpassen von Eigenschaften wie der Position und Skalierung von Objekten hat sich im Rahmen dieser Iteration bereits als nützlich erwiesen und kann ebenfalls implementiert werden, da herausgefunden wurde das die Modellierer diese Funktion auch nutzen.
Dadurch wird eine Grundlage für weitere Interaktionsmöglichkeiten dieser Art gelegt.
So ist es beispielsweise üblich die Eigenschaften, die nun gemeinsam anpassbar sind, mit Datapoolitems zu verlinken.
Bei den Befragungen nach den Test äußern hier einige der Nutzer den Wunsch diese Verlinkung ebenfalls mithilfe der Multiselektion durchführen zu können, was es für eine weitere Iteration im Prototyp ergänzt und evaluiert werden kann.
Zusätzlich wird angegeben das über dem Propertiespanel angezeigt werden soll welche Objekte aktuell zusammen ausgewählt sind, da dies bis jetzt nur im View erkennbar ist.

Da bei den durchgeführten Tests deutlich wird das die Nutzer sich für die Alignment Actions interessieren kann nun in folgenden Iterationen noch eine Verbesserung und Erweiterung der Funktionalitäten angestrebt werden.
Für diesen Test war der Prototyp so ausgelegt das bereits bekannt war welches der drei Bilder des Hauptmenüs links, rechts und in der Mitte liegt.
Dadurch hat sich die Anordnung durch einen Klick auf den Button automatisch an die Spezifikation angepasst.
Für tatsächliche Arbeitsabläufe ist dies nicht der Fall, weshalb es für den Nutzer noch möglich sein muss anzugeben in welcher Anordnung die Bilder platziert werden müssen.
Dies wäre zum Beispiel dadurch machbar das der Nutzer ein Objekt als Ausrichtungspunkt deklarieren kann.

Die Multiselektion bietet also noch viele Möglichkeiten die in weiteren Durchführungen des Human Centered Design Process den Prototyp zu ergänzen und die neuen Funktionen zu evaluieren, die Funktion  \glqq Insert in Template\grqq{} gilt es jedoch zum aktuellen Zeitpunkt wieder zu verwerfen.